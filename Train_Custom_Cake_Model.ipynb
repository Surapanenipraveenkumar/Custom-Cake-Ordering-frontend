{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# ðŸŽ‚ Train Custom Cake AI Model + Export to ONNX\n",
                "\n",
                "## Setup:\n",
                "1. **Runtime â†’ Change runtime type â†’ T4 GPU**\n",
                "2. Run all cells in order\n",
                "\n",
                "---"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 1: Install Required Libraries\n",
                "!pip install -q diffusers==0.25.0 transformers accelerate peft datasets huggingface_hub\n",
                "!pip install -q onnx onnxruntime-gpu optimum[onnxruntime]\n",
                "!pip install -q bitsandbytes safetensors\n",
                "print(\"âœ… Libraries installed!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 2: Login to Hugging Face\n",
                "from huggingface_hub import notebook_login\n",
                "print(\"ðŸ” Get token from: https://huggingface.co/settings/tokens\\n\")\n",
                "notebook_login()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 3: Load Your Cake Images Dataset\n",
                "from datasets import load_dataset\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "print(\"ðŸ“¥ Loading cake images dataset...\")\n",
                "dataset = load_dataset(\"praveen9025/cake-images\", split=\"train\")\n",
                "print(f\"âœ… Loaded {len(dataset)} images!\")\n",
                "\n",
                "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
                "for i, ax in enumerate(axes):\n",
                "    ax.imshow(dataset[i]['image'])\n",
                "    ax.axis('off')\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 4: Prepare Training Data\n",
                "import os\n",
                "from PIL import Image\n",
                "\n",
                "TRAIN_DIR = \"cake_training_data\"\n",
                "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
                "\n",
                "CAPTION = \"a professional photo of cakestyle cake, bakery, studio lighting\"\n",
                "\n",
                "print(\"ðŸ“ Preparing training data...\")\n",
                "for i, item in enumerate(dataset):\n",
                "    img = item['image'].convert('RGB').resize((512, 512), Image.LANCZOS)\n",
                "    img.save(os.path.join(TRAIN_DIR, f\"cake_{i:03d}.png\"))\n",
                "    with open(os.path.join(TRAIN_DIR, f\"cake_{i:03d}.txt\"), 'w') as f:\n",
                "        f.write(CAPTION)\n",
                "\n",
                "print(f\"âœ… Prepared {len(dataset)} images!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 5: Clone Diffusers\n",
                "!git clone https://github.com/huggingface/diffusers.git\n",
                "!pip install -q -r diffusers/examples/dreambooth/requirements_sdxl.txt\n",
                "print(\"âœ… Training scripts ready!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 6: Configure Accelerate\n",
                "!accelerate config default\n",
                "print(\"âœ… Accelerate configured!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 7: Train LoRA Model (30-60 minutes)\n",
                "import os\n",
                "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
                "\n",
                "print(\"ðŸš€ Starting training... â˜• This takes 30-60 minutes\\n\")\n",
                "\n",
                "!accelerate launch diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py \\\n",
                "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
                "  --instance_data_dir=\"cake_training_data\" \\\n",
                "  --output_dir=\"cake-lora-model\" \\\n",
                "  --instance_prompt=\"a photo of cakestyle cake\" \\\n",
                "  --resolution=512 \\\n",
                "  --train_batch_size=1 \\\n",
                "  --gradient_accumulation_steps=4 \\\n",
                "  --gradient_checkpointing \\\n",
                "  --learning_rate=1e-4 \\\n",
                "  --lr_scheduler=\"constant\" \\\n",
                "  --lr_warmup_steps=0 \\\n",
                "  --max_train_steps=500 \\\n",
                "  --rank=16 \\\n",
                "  --mixed_precision=\"fp16\" \\\n",
                "  --seed=42\n",
                "\n",
                "print(\"\\nâœ… Training complete!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 8: Check what files were created\n",
                "import os\n",
                "\n",
                "print(\"ðŸ“ Files in cake-lora-model:\")\n",
                "for root, dirs, files in os.walk(\"cake-lora-model\"):\n",
                "    for file in files:\n",
                "        filepath = os.path.join(root, file)\n",
                "        size_mb = os.path.getsize(filepath) / (1024*1024)\n",
                "        print(f\"  {filepath} ({size_mb:.2f} MB)\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 9: Load and Merge LoRA (FIXED VERSION)\n",
                "from diffusers import DiffusionPipeline, AutoencoderKL\n",
                "import torch\n",
                "import os\n",
                "\n",
                "print(\"ðŸ”— Merging LoRA weights into base model...\")\n",
                "\n",
                "# Load base model\n",
                "vae = AutoencoderKL.from_pretrained(\n",
                "    \"madebyollin/sdxl-vae-fp16-fix\", \n",
                "    torch_dtype=torch.float16\n",
                ")\n",
                "\n",
                "pipe = DiffusionPipeline.from_pretrained(\n",
                "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
                "    vae=vae,\n",
                "    torch_dtype=torch.float16,\n",
                ").to(\"cuda\")\n",
                "\n",
                "# Find the correct LoRA weights file\n",
                "lora_dir = \"cake-lora-model\"\n",
                "possible_files = [\n",
                "    \"pytorch_lora_weights.safetensors\",\n",
                "    \"pytorch_lora_weights.bin\",\n",
                "]\n",
                "\n",
                "lora_file = None\n",
                "for f in possible_files:\n",
                "    if os.path.exists(os.path.join(lora_dir, f)):\n",
                "        lora_file = f\n",
                "        break\n",
                "\n",
                "if lora_file:\n",
                "    print(f\"ðŸ“„ Found LoRA weights: {lora_file}\")\n",
                "    pipe.load_lora_weights(lora_dir, weight_name=lora_file)\n",
                "    pipe.fuse_lora()\n",
                "    print(\"âœ… LoRA weights merged!\")\n",
                "else:\n",
                "    print(\"âŒ No LoRA weights found. Check training output.\")\n",
                "    print(f\"Files in {lora_dir}:\", os.listdir(lora_dir) if os.path.exists(lora_dir) else \"Directory not found\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 10: Test the merged model\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "print(\"ðŸŽ¨ Testing merged model...\")\n",
                "\n",
                "prompt = \"a photo of cakestyle chocolate birthday cake with sprinkles\"\n",
                "image = pipe(prompt, num_inference_steps=25).images[0]\n",
                "\n",
                "plt.figure(figsize=(8, 8))\n",
                "plt.imshow(image)\n",
                "plt.axis('off')\n",
                "plt.title(\"Test: \" + prompt[:40] + \"...\")\n",
                "plt.savefig(\"test_result.png\")\n",
                "plt.show()\n",
                "\n",
                "print(\"âœ… Model works!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 11: Save merged model\n",
                "MERGED_MODEL_PATH = \"cake-model-merged\"\n",
                "\n",
                "print(f\"ðŸ’¾ Saving merged model to {MERGED_MODEL_PATH}...\")\n",
                "pipe.save_pretrained(MERGED_MODEL_PATH)\n",
                "print(\"âœ… Merged model saved!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 12: Export to ONNX\n",
                "from optimum.onnxruntime import ORTStableDiffusionXLPipeline\n",
                "\n",
                "ONNX_OUTPUT_DIR = \"cake-model-onnx\"\n",
                "\n",
                "print(\"ðŸ“¦ Exporting to ONNX format...\")\n",
                "print(\"â±ï¸ This takes 10-20 minutes...\\n\")\n",
                "\n",
                "onnx_pipe = ORTStableDiffusionXLPipeline.from_pretrained(\n",
                "    MERGED_MODEL_PATH,\n",
                "    export=True,\n",
                ")\n",
                "\n",
                "onnx_pipe.save_pretrained(ONNX_OUTPUT_DIR)\n",
                "\n",
                "print(f\"\\nâœ… ONNX model saved to: {ONNX_OUTPUT_DIR}\")\n",
                "!ls -la {ONNX_OUTPUT_DIR}"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 13: Download ONNX Model\n",
                "import shutil\n",
                "import os\n",
                "\n",
                "ZIP_NAME = \"cake-model-onnx.zip\"\n",
                "\n",
                "print(f\"ðŸ“¦ Creating {ZIP_NAME}...\")\n",
                "shutil.make_archive(\"cake-model-onnx\", 'zip', ONNX_OUTPUT_DIR)\n",
                "\n",
                "print(f\"\\nâœ… Created: {ZIP_NAME}\")\n",
                "print(f\"ðŸ“ Size: {os.path.getsize(ZIP_NAME) / (1024*1024*1024):.2f} GB\")\n",
                "print(f\"\\nâ¬‡ï¸ Download from Files panel on the left\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 14: Save to Google Drive\n",
                "from google.colab import drive\n",
                "import shutil\n",
                "\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "# Copy zip to Drive\n",
                "shutil.copy(\"cake-model-onnx.zip\", \"/content/drive/MyDrive/\")\n",
                "\n",
                "print(\"\\nâœ… Saved to Google Drive!\")\n",
                "print(\"ðŸ“ Google Drive > cake-model-onnx.zip\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## âœ… Done!\n",
                "\n",
                "Your ONNX model is ready!\n",
                "\n",
                "**Usage:**\n",
                "```python\n",
                "from optimum.onnxruntime import ORTStableDiffusionXLPipeline\n",
                "\n",
                "pipe = ORTStableDiffusionXLPipeline.from_pretrained(\"cake-model-onnx\")\n",
                "image = pipe(\"a photo of cakestyle chocolate cake\").images[0]\n",
                "```\n",
                "\n",
                "---"
            ],
            "metadata": {}
        }
    ]
}