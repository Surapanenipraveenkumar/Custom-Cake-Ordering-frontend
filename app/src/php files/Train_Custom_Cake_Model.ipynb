{
    "nbformat": 4,
    "nbformat_minor": 0,
    "metadata": {
        "colab": {
            "provenance": [],
            "gpuType": "T4"
        },
        "kernelspec": {
            "name": "python3",
            "display_name": "Python 3"
        },
        "accelerator": "GPU"
    },
    "cells": [
        {
            "cell_type": "markdown",
            "source": [
                "# ðŸŽ‚ Train Custom Cake AI Model + Export to ONNX\n",
                "\n",
                "This notebook:\n",
                "1. Trains a custom cake model using **LoRA** on SDXL\n",
                "2. Exports to **ONNX format** for local/mobile deployment\n",
                "\n",
                "## Setup:\n",
                "1. **Runtime â†’ Change runtime type â†’ T4 GPU**\n",
                "2. Run all cells in order\n",
                "\n",
                "---"
            ],
            "metadata": {}
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 1: Install Required Libraries\n",
                "!pip install -q diffusers transformers accelerate peft datasets huggingface_hub\n",
                "!pip install -q onnx onnxruntime-gpu optimum[onnxruntime]\n",
                "print(\"âœ… Libraries installed!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 2: Login to Hugging Face\n",
                "from huggingface_hub import notebook_login\n",
                "\n",
                "print(\"ðŸ” Login to Hugging Face\")\n",
                "print(\"Get token from: https://huggingface.co/settings/tokens\\n\")\n",
                "\n",
                "notebook_login()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 3: Load Your Cake Images Dataset\n",
                "from datasets import load_dataset\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "print(\"ðŸ“¥ Loading your cake images dataset...\")\n",
                "dataset = load_dataset(\"praveen9025/cake-images\", split=\"train\")\n",
                "print(f\"âœ… Loaded {len(dataset)} cake images!\")\n",
                "\n",
                "# Preview\n",
                "fig, axes = plt.subplots(1, 4, figsize=(16, 4))\n",
                "for i, ax in enumerate(axes):\n",
                "    ax.imshow(dataset[i]['image'])\n",
                "    ax.axis('off')\n",
                "plt.show()"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 4: Prepare Training Data\n",
                "import os\n",
                "from PIL import Image\n",
                "\n",
                "TRAIN_DIR = \"cake_training_data\"\n",
                "os.makedirs(TRAIN_DIR, exist_ok=True)\n",
                "\n",
                "CAPTION = \"a professional photo of cakestyle cake, bakery, studio lighting\"\n",
                "\n",
                "print(\"ðŸ“ Preparing training data...\")\n",
                "for i, item in enumerate(dataset):\n",
                "    img = item['image'].convert('RGB').resize((512, 512), Image.LANCZOS)\n",
                "    img.save(os.path.join(TRAIN_DIR, f\"cake_{i:03d}.png\"))\n",
                "    with open(os.path.join(TRAIN_DIR, f\"cake_{i:03d}.txt\"), 'w') as f:\n",
                "        f.write(CAPTION)\n",
                "\n",
                "print(f\"âœ… Prepared {len(dataset)} images!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 5: Clone Diffusers Training Scripts\n",
                "!git clone https://github.com/huggingface/diffusers.git\n",
                "!pip install -q ./diffusers\n",
                "print(\"âœ… Training scripts ready!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 6: Train LoRA Model (30-60 minutes)\n",
                "print(\"ðŸš€ Starting training... â˜• Coffee break time!\\n\")\n",
                "\n",
                "!accelerate launch diffusers/examples/dreambooth/train_dreambooth_lora_sdxl.py \\\n",
                "  --pretrained_model_name_or_path=\"stabilityai/stable-diffusion-xl-base-1.0\" \\\n",
                "  --instance_data_dir=\"cake_training_data\" \\\n",
                "  --output_dir=\"cake-lora-model\" \\\n",
                "  --instance_prompt=\"a photo of cakestyle cake\" \\\n",
                "  --resolution=512 \\\n",
                "  --train_batch_size=1 \\\n",
                "  --gradient_accumulation_steps=4 \\\n",
                "  --learning_rate=1e-4 \\\n",
                "  --max_train_steps=500 \\\n",
                "  --rank=32 \\\n",
                "  --mixed_precision=\"fp16\"\n",
                "\n",
                "print(\"\\nâœ… Training complete!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 7: Merge LoRA weights into base model (required for ONNX export)\n",
                "from diffusers import DiffusionPipeline, AutoencoderKL\n",
                "import torch\n",
                "\n",
                "print(\"ðŸ”— Merging LoRA weights into base model...\")\n",
                "\n",
                "# Load base model\n",
                "vae = AutoencoderKL.from_pretrained(\n",
                "    \"madebyollin/sdxl-vae-fp16-fix\", \n",
                "    torch_dtype=torch.float16\n",
                ")\n",
                "\n",
                "pipe = DiffusionPipeline.from_pretrained(\n",
                "    \"stabilityai/stable-diffusion-xl-base-1.0\",\n",
                "    vae=vae,\n",
                "    torch_dtype=torch.float16,\n",
                ").to(\"cuda\")\n",
                "\n",
                "# Load and merge LoRA\n",
                "pipe.load_lora_weights(\"cake-lora-model\")\n",
                "pipe.fuse_lora()  # Merge LoRA into base weights\n",
                "\n",
                "# Save merged model\n",
                "MERGED_MODEL_PATH = \"cake-model-merged\"\n",
                "pipe.save_pretrained(MERGED_MODEL_PATH)\n",
                "\n",
                "print(f\"âœ… Merged model saved to: {MERGED_MODEL_PATH}\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 8: Export to ONNX Format! ðŸŽ‰\n",
                "from optimum.onnxruntime import ORTStableDiffusionXLPipeline\n",
                "\n",
                "ONNX_OUTPUT_DIR = \"cake-model-onnx\"\n",
                "\n",
                "print(\"ðŸ“¦ Exporting to ONNX format...\")\n",
                "print(\"â±ï¸ This takes 10-15 minutes...\\n\")\n",
                "\n",
                "# Export using Optimum\n",
                "onnx_pipe = ORTStableDiffusionXLPipeline.from_pretrained(\n",
                "    MERGED_MODEL_PATH,\n",
                "    export=True,\n",
                ")\n",
                "\n",
                "# Save ONNX model\n",
                "onnx_pipe.save_pretrained(ONNX_OUTPUT_DIR)\n",
                "\n",
                "print(f\"\\nâœ… ONNX model saved to: {ONNX_OUTPUT_DIR}\")\n",
                "print(f\"ðŸ“ Files created:\")\n",
                "!ls -la {ONNX_OUTPUT_DIR}"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 9: Test ONNX Model\n",
                "from optimum.onnxruntime import ORTStableDiffusionXLPipeline\n",
                "import matplotlib.pyplot as plt\n",
                "\n",
                "print(\"ðŸ§ª Testing ONNX model...\")\n",
                "\n",
                "# Load ONNX model\n",
                "onnx_pipe = ORTStableDiffusionXLPipeline.from_pretrained(ONNX_OUTPUT_DIR)\n",
                "\n",
                "# Generate test image\n",
                "prompt = \"a photo of cakestyle chocolate birthday cake with sprinkles\"\n",
                "image = onnx_pipe(prompt, num_inference_steps=20).images[0]\n",
                "\n",
                "plt.figure(figsize=(8, 8))\n",
                "plt.imshow(image)\n",
                "plt.axis('off')\n",
                "plt.title(\"ONNX Generated Cake\")\n",
                "plt.savefig(\"onnx_test_result.png\")\n",
                "plt.show()\n",
                "\n",
                "print(\"âœ… ONNX model working!\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 10: Download ONNX Model to Your Computer\n",
                "import shutil\n",
                "\n",
                "# Create zip file for easy download\n",
                "ZIP_NAME = \"cake-model-onnx.zip\"\n",
                "\n",
                "print(f\"ðŸ“¦ Creating {ZIP_NAME}...\")\n",
                "shutil.make_archive(\"cake-model-onnx\", 'zip', ONNX_OUTPUT_DIR)\n",
                "\n",
                "print(f\"\\nâœ… ONNX model packaged!\")\n",
                "print(f\"ðŸ“ File size: {os.path.getsize(ZIP_NAME) / (1024*1024*1024):.2f} GB\")\n",
                "print(f\"\\nâ¬‡ï¸ Download 'cake-model-onnx.zip' from the Files panel on the left\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "code",
            "source": [
                "# Step 11: (Optional) Save to Google Drive\n",
                "from google.colab import drive\n",
                "\n",
                "print(\"ðŸ’¾ Saving to Google Drive...\")\n",
                "drive.mount('/content/drive')\n",
                "\n",
                "DRIVE_PATH = \"/content/drive/MyDrive/cake-model-onnx\"\n",
                "\n",
                "# Copy to Drive\n",
                "if os.path.exists(DRIVE_PATH):\n",
                "    shutil.rmtree(DRIVE_PATH)\n",
                "shutil.copytree(ONNX_OUTPUT_DIR, DRIVE_PATH)\n",
                "\n",
                "# Also copy zip\n",
                "shutil.copy(ZIP_NAME, \"/content/drive/MyDrive/\")\n",
                "\n",
                "print(f\"\\nâœ… ONNX model saved to Google Drive!\")\n",
                "print(f\"ðŸ“ Location: Google Drive > cake-model-onnx\")"
            ],
            "metadata": {},
            "execution_count": null,
            "outputs": []
        },
        {
            "cell_type": "markdown",
            "source": [
                "---\n",
                "## âœ… Done!\n",
                "\n",
                "Your custom cake model is now in **ONNX format**!\n",
                "\n",
                "### ONNX Files Created:\n",
                "| File | Description |\n",
                "|------|-------------|\n",
                "| `text_encoder/model.onnx` | Text encoder |\n",
                "| `unet/model.onnx` | Main diffusion model |\n",
                "| `vae_decoder/model.onnx` | VAE decoder |\n",
                "| `vae_encoder/model.onnx` | VAE encoder |\n",
                "\n",
                "### Use Cases:\n",
                "- **Local Python:** `ORTStableDiffusionXLPipeline.from_pretrained(\"cake-model-onnx\")`\n",
                "- **Mobile (Android):** Use ONNX Runtime Mobile\n",
                "- **Web:** Use ONNX.js or Transformers.js\n",
                "\n",
                "---"
            ],
            "metadata": {}
        }
    ]
}